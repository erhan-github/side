"""
Data aggregation layer - Pure math, no LLM inference.

Compresses raw data (1000 days) into structured summaries
for token-efficient LLM prompting.

Forensic-level principles:
- Pure math (no inference)
- 100% accuracy (no hallucination)
- Zero cost (no LLM calls)
- Defensive coding (silent failures)
"""

from typing import Dict, List, Optional
from datetime import datetime, timedelta, timezone
from collections import Counter
import statistics


class DataAggregator:
    """
    Pre-process data before LLM analysis.
    
    Converts raw data â†’ structured summaries with 1000x token reduction.
    """
    
    def __init__(self, db):
        self.db = db
    
    def aggregate_velocity(self, days: int = 1000) -> Dict:
        """
        Aggregate velocity data with pure math.
        
        Args:
            days: Number of days to analyze
            
        Returns:
            {
                'baseline': float,  # Commits/day (Day 1-7)
                'current': float,   # Commits/day (Last 7 days)
                'delta_pct': float, # Percentage change
                'trend': str,       # 'accelerating', 'stable', 'declining'
                'confidence': float # 0.95 (math-based)
            }
        """
        try:
            # Get commits
            since = datetime.now(timezone.utc) - timedelta(days=days)
            commits = self.db.get_commits_since(since.isoformat())
            
            if not commits:
                return self._empty_velocity_result()
            
            # Calculate baseline (first 7 days)
            baseline_commits = [c for c in commits if self._days_ago(c) >= days - 7]
            baseline = len(baseline_commits) / 7.0 if baseline_commits else 0
            
            # Calculate current (last 7 days)
            current_commits = [c for c in commits if self._days_ago(c) <= 7]
            current = len(current_commits) / 7.0 if current_commits else 0
            
            # Calculate delta
            if baseline > 0:
                delta_pct = ((current - baseline) / baseline) * 100
            else:
                delta_pct = 0
            
            # Detect trend (analyze monthly velocities)
            trend = self._detect_velocity_trend(commits, days)
            
            return {
                'baseline': round(baseline, 1),
                'current': round(current, 1),
                'delta_pct': round(delta_pct, 1),
                'trend': trend,
                'confidence': 0.95  # High confidence (pure math)
            }
        except Exception as e:
            # Silent failure - return empty result
            return self._empty_velocity_result()
    
    def aggregate_focus(self, days: int = 30) -> Dict:
        """
        Aggregate focus areas (where time is spent).
        
        Returns:
            {
                'backend_pct': float,
                'frontend_pct': float,
                'docs_pct': float,
                'top_files': List[str],
                'confidence': float
            }
        """
        try:
            since = datetime.now(timezone.utc) - timedelta(days=days)
            file_changes = self.db.get_file_changes_since(since.isoformat())
            
            if not file_changes:
                return self._empty_focus_result()
            
            # Categorize files
            backend = sum(1 for f in file_changes if self._is_backend(f))
            frontend = sum(1 for f in file_changes if self._is_frontend(f))
            docs = sum(1 for f in file_changes if self._is_docs(f))
            total = len(file_changes)
            
            # Calculate percentages
            backend_pct = (backend / total * 100) if total > 0 else 0
            frontend_pct = (frontend / total * 100) if total > 0 else 0
            docs_pct = (docs / total * 100) if total > 0 else 0
            
            # Get top files
            file_counts = Counter(file_changes)
            top_files = [f for f, _ in file_counts.most_common(5)]
            
            return {
                'backend_pct': round(backend_pct, 1),
                'frontend_pct': round(frontend_pct, 1),
                'docs_pct': round(docs_pct, 1),
                'top_files': top_files,
                'confidence': 0.95
            }
        except Exception:
            return self._empty_focus_result()
    
    def aggregate_costs(self, days: int = 30) -> Dict:
        """
        Aggregate costs by feature.
        
        Returns:
            {
                'by_feature': {'audit': 12.40, 'simulate': 8.20, ...},
                'total': float,
                'top_feature': str,
                'top_feature_pct': float,
                'confidence': float
            }
        """
        try:
            since = datetime.now(timezone.utc) - timedelta(days=days)
            activities = self.db.get_activities_since(since.isoformat())
            
            if not activities:
                return self._empty_costs_result()
            
            # Calculate costs per feature
            costs = {}
            llm_cost_per_token = 0.0001  # $0.0001 per token
            
            for activity in activities:
                tool = activity.get('tool', 'unknown')
                tokens = activity.get('cost_tokens', 0)
                cost = tokens * llm_cost_per_token
                costs[tool] = costs.get(tool, 0) + cost
            
            total = sum(costs.values())
            
            # Find top feature
            if costs:
                top_feature = max(costs.items(), key=lambda x: x[1])
                top_feature_name = top_feature[0]
                top_feature_cost = top_feature[1]
                top_feature_pct = (top_feature_cost / total * 100) if total > 0 else 0
            else:
                top_feature_name = None
                top_feature_pct = 0
            
            return {
                'by_feature': {k: round(v, 2) for k, v in costs.items()},
                'total': round(total, 2),
                'top_feature': top_feature_name,
                'top_feature_pct': round(top_feature_pct, 1),
                'confidence': 1.0  # Perfect (from logs)
            }
        except Exception:
            return self._empty_costs_result()
    
    def _detect_velocity_trend(self, commits: List, days: int) -> str:
        """Detect if velocity is accelerating, stable, or declining."""
        try:
            # Group by month
            monthly_velocities = []
            for month_offset in range(0, min(days // 30, 12)):
                start_day = month_offset * 30
                end_day = (month_offset + 1) * 30
                
                month_commits = [
                    c for c in commits
                    if start_day <= self._days_ago(c) < end_day
                ]
                velocity = len(month_commits) / 30.0
                monthly_velocities.append(velocity)
            
            if len(monthly_velocities) < 3:
                return 'stable'
            
            # Check last 3 months
            recent_3 = monthly_velocities[-3:]
            
            # All increasing = accelerating
            if all(recent_3[i] < recent_3[i+1] for i in range(len(recent_3)-1)):
                return 'accelerating'
            
            # All within 5% = stable
            avg = statistics.mean(recent_3)
            if all(abs(v - avg) / avg < 0.05 for v in recent_3 if avg > 0):
                return 'stable'
            
            # Otherwise declining
            return 'declining'
        except Exception:
            return 'stable'
    
    def _days_ago(self, commit: Dict) -> int:
        """Calculate days ago for a commit."""
        try:
            commit_time = datetime.fromisoformat(commit['created_at'])
            delta = datetime.now(timezone.utc) - commit_time
            return delta.days
        except Exception:
            return 0
    
    def _is_backend(self, file_path: str) -> bool:
        """Check if file is backend code."""
        return file_path.endswith('.py') and 'backend' in file_path
    
    def _is_frontend(self, file_path: str) -> bool:
        """Check if file is frontend code."""
        return (file_path.endswith(('.ts', '.tsx', '.jsx')) and 
                ('web' in file_path or 'frontend' in file_path))
    
    def _is_docs(self, file_path: str) -> bool:
        """Check if file is documentation."""
        return file_path.endswith('.md')
    
    def _empty_velocity_result(self) -> Dict:
        """Return empty velocity result."""
        return {
            'baseline': 0,
            'current': 0,
            'delta_pct': 0,
            'trend': 'stable',
            'confidence': 0
        }
    
    def _empty_focus_result(self) -> Dict:
        """Return empty focus result."""
        return {
            'backend_pct': 0,
            'frontend_pct': 0,
            'docs_pct': 0,
            'top_files': [],
            'confidence': 0
        }
    
    def _empty_costs_result(self) -> Dict:
        """Return empty costs result."""
        return {
            'by_feature': {},
            'total': 0,
            'top_feature': None,
            'top_feature_pct': 0,
            'confidence': 0
        }
