To view keyboard shortcuts, press question mark
View keyboard shortcuts
Article

See new posts
Conversation
dei
@parcadei
WTF is a Context Graph? A Guide to the Trillion-Dollar Problem  
You’ve read 15 articles, skimmed 12 threads and watched 4 podcasts but you still can't answer "what is a context graph?" Allow me to confuse you further...
Origin Story
It all started with “Long Live Systems of Record” by @jaminball. His response to the idea that “Agents are the new system of record”. Jamin’s argument is that agents don’t replace systems of record, they raise the bar of what a good one looks like.  
What is a system of record? 

A system of record is basically “THE” data storage system that serves as the storage layer for specific data needs within an organisation and is the canonical source of truth. 
CRM is a system of record for customer data
ERP is a system of record for financial data   
HRIS is a system of record for employee data
X is a system of record for my unhinged psyche
If we take a look at what happened, over time as data grew in size,  systems of records became places where information was exchanged and updated. 

Data warehouses and lakehouses became the places it was fed into.  
Wait, lakehouse, warehouse - what’s beachfront property and logistics got to do with any of this?   
Imagine a data warehouse is like a filing cabinet where everything is labeled and kept neat, or like an actual warehouse. 

A lakehouse merges a ‘data lake’ with a ‘data warehouse’; so you have your storage of unstructured data streaming in and your filing system in one place.
They give a company a unified view of all their data to view all their data.
Jamin, rightly so, points out that the source of truth isn’t a product category, it’s the backstop for agent quality because if the agent pulls the wrong piece of data, everything downstream is wrong.
And these systems were designed for humans, which means that they’re not inherently ‘agent-friendly’. 

And the next logical step is a queryable layer for agents. His core conclusion is that system of records won’t die, they’ll just change shape.   The warehouses and lakehouses becomes the read layer, and the system of records become the write layer for agents.  

And where you end up with a “state machines with APIs”
What’s a state machine and API?   

A state machine is something that reads a set of inputs and changes to a different state based on those inputs. An API is the connection between the agent and that machine, i.e. how it sends and receives inputs and outputs.  
So this means that CRMs/ERPs don’t disappear, they just stop being places humans spend their time in, and become the home for agents instead.  
So you’re saying we just hook up agents to data houses and systems of records, and we’re good to go?  

Well, not exactly...
In her article,  “AI’s trillion-dollar opportunity: Context graphs” @jayagup10's core claim is that whilst agents need better access to existing data, governance and semantic rule. It’s not the full picture.    
For the agent to be able to truly live in the execution path, they need decision traces. Which is the reasoning that connects data to action, and the main problem is that this was never treated as data in the first place.     
The distinction is basically rules are what should happen and decision traces are what actually happened and why.    
Can’t incumbents build this?
 Not according to Jaya, warehouses exist in the read path so they can’t append ‘decisions data’ after the fact.    
And system of records that exist are siloed which means that  they inherent the systems limitations (i.e. Salesforce is built on current state, and you can’t replay the state of the world at decision time)  
And the clearest signal this is needed is that roles such as DevOps, RevOps, SecOps, etc exist.   
They are the bridge between different areas of a business that don’t natively work together - the ‘human glue’ - which means they carry context that isn’t tracked natively in the current systems.   
To quote Jaya, 
“The interesting surfaces are where the logic is complex, where precedent matters, and where “it depends” is the honest answer.”   
QUICK RECAP:
System of Records (Write Layer) & Warehouse (Read Layer) exist for humans to manage data.  
The next step is a queryable layer where the agents live, and humans spend more time orchestrating agents than they do interacting with the data
For an agent to be able to truly be effective, we need to capture the context that lives inside human minds and nothing exists that does this.    
And once you do, every trace becomes a searchable path and every automated decision adds another trace and the graph compounds over time. 
And that’s the trillion dollar opportunity.   
At least, that's Jaya’s framing as I understand it. But not everyone agrees on what a context graph actually is or how to build one.  
And why is it called Context Graph instead of Decision Trace Capture?  
Easy baby, context sells.    
Part 2: How To Build A Context Graph
A new player steps into the arena: @akoratana
His article "How To Build A Context Graph" succinctly points out that most of the existing infrastructure we have for data exists for what’s true now.
Nothing exists for why it became true. And this is because humans were the reasoning layer; which echoes Jaya’s sentiment that the existence of operational roles is the highest signal for why we need Context Graphs.  
He goes on to explain      
I call this the two clocks problem. Every system has a state clock—what's true right now—and an event clock—what happened, in what order, with what reasoning. We've built elaborate infrastructure for the state clock. The event clock barely exists.”  
The examples in the article are apt, timeout=30s and previously it was 5 seconds but nothing states why it was changed, the reasoning was never captured. 
He goes on to say that theres three factors that make this hard:  
1. Most systems aren’t  fully observable so you can’t capture reasoning about things you can’t see
2. There’s no universal ontology. Every organisation has its own entities, relationships and semantics.
3. The system is always changing which means you’re not documenting static reality, you’re tracking change.
Which begs the question, how do you build an event clock for a system you can’t fully see, can’t fully schema and can’t hold still? 
His solution boils down to using Agents as Informed Walkers.
The trail created when an agent operates within an organisation allows you to create an event clock. 
The ontology (a structured description of what exists in some area and how those things relate together) emerges from their walk which is built on real work.   
And here we take the next spin: Context Graphs are World Models.   
What is a world model?    
In his words:   
“A world model is a learned, compressed representation of how an environment works. It encodes dynamics, ie. what happens when you take actions suspended in a specific state. It captures structure: what entities exist and how they relate. And it enables prediction: given a current state and a proposed action, what happens next?”    
Essentially, a world model is a ‘map to the territory’ for an agent to understand the environment it operates in.  
And his following conclusion of “A context graph with enough accumulated structure becomes a world model for organizational physics. It encodes how decisions unfold, how state changes propagate, how entities interact. Once you have that, you can simulate.”  

Agent walks the path, outputs a schema which compounds over time so that a world model develops. In theory, this means you don’t have to sit and sift through all your data to build your own schemas.   
However there’s a few problems I see with this frame:   
Agents aren’t truly “informed walkers”, they’re walkers who infer. Their output is dependent on what fits inside their context window, which means once wrong interpretation and the accumulated schema is corrupted.     
The node2vec analogy works but undermines the point, because node2vec works because it’s a deterministic algorithm running over a known graph. The graph has to exist first because you can’t map what hasn’t been seen. 
Which brings us to the fourth entrant of the arena: @KirkMarple
In his own words from "Context Graphs: What the Ontology Debate Gets Wrong":  
“My argument is simple: entity ontologies are largely solved by existing standards. The real unsolved work is temporal validity, decision traces, and fact resolution. Learning helps there—not at the entity layer. The dichotomy isn't prescribed vs learned. It's adopt foundations, then learn what's novel.”    
He aptly points out that the debate is being framed as “prescribed ontologies” vs “learned ontologies”.  
The structure either is mapped upfront which is expensive, slow and hard to scale without team of forward deployed engineers over a period of months or emerges from when work happens, and it’s discovered.
But...
“There's just one problem: it ignores twenty years of ontology work that already exists.”  
He highlights that there exists a third option; “Adopt what exists. Extend where needed. Focus learning on what's genuinely novel.”  
Ontologies already exist - schema.org defines Person, Organisation, Place, etc and is in production across billions of webpages. 
Microsofts Common Data Model was license to WAND, who have been building enterprise taxonomies for decades.
The wheel doesn’t need to be reinvented, you just need to pick a car.
Palantir is expensive because they build bespoke for every deployment instead of leveraging what exists, that’s a business model choice, not a technical necessity. 
And the point “you can’t wait for a thousand agent RAG runs to ‘discover’ Sarah is a person who works at ACME because you need to know that before the agent runs” holds because it’s computationally expensive, slow and unnecessary work.
“Where inference genuinely helps: discovering which custom fields actually matter, which relationships get used, which objects are central vs peripheral to how this specific team works. That's organizational intelligence on top of a foundation—not the foundation itself.”   
The learned ontology vision conflates two very different problems:

Entity modeling: What types of things exist and how do they relate? (Solved—or at least solvable with existing standards)

Organizational intelligence: How does this specific organization actually work? What patterns govern decisions? (Genuinely novel, genuinely requires learning)
And here we arrive at the practical answer of “adopt existing ontologies as the foundation, then let learning refine and extend.”  His recommendation is:
 Entity modeling: 

Adopt existing standards. Don't spend months defining what an Account is. Microsoft already licensed that from WAND.
Temporal validity:

This is where the work is. Facts that change over time. The ability to query historical state. The event clock.
Decision traces:

This is where the opportunity is. Being in the execution path. Capturing reasoning as data.
Fact resolution:

This is where the hard AI problems live. Using LLMs to determine what's canonical, what's superseded, how to synthesize timeline facts from scattered observations.
Organizational learning: 

This is where trajectories genuinely help—but on top of a foundation, not instead of one.

I'd recommend reading his article because he goes into further detail far more elegantly than I am if you want his complete take since I'm short on time and context.

So far we've got: decision traces, event clocks, world models, adopted ontologies, temporal layers.
But we've still not answered the question: what actually is a context graph?
Part 3: The Definition Problem
Here we can turn to @trustspooky's article "The Context Graph Manifesto"
His definition: "Put simply, a context graph is a triples-representation of data that is optimised for usage with AI."
Wait, what about decision traces, event clocks, world models, adopted ontologies, temporal layers???
Exactly. Welcome to the definition problem.
He's quick to point out that the knowledge graph community is "extremely evangelical about what the 'right way' is." 
Sit around a table of knowledge graph experts, ask "what is a knowledge graph?" and just wait for the arguments to begin.
So what's his actual position?
There is no single right way.
"You can use RDF or property graphs to store the same information. No matter what any 'expert' claims, you can store the same information as a triplestore, property graph, or even as joined tables."
TrustGraph's default store is Apache Cassandra and one of their users has over a billion nodes loaded in Cassandra. Does it matter that it's not a "proper" graph store? The agents don't seem to care.
LLMs changed the game.
The semantic web's vision was machine-readable data everywhere using RDFs and URIs. It would allow interoperability and create a utopia for machines. 
The problem was the syntax, RDF, SPARQL, OWL. The learning curve was brutal and excluding its use in some organisations, it never clicked everywhere else.
But David points out that LLMs bypass this entirely. They can read JSON, RDF, Cypher, whatever you throw at them - which makes the format you use a design choice.
So Daniel's position is: a context graph is a methodology, not a specification. 
Use whatever structure works for your use case. The "context" part is that it's optimised for LLM retrieval.
Now here @kidehen  disagrees and respond with a reasonable challenge:
"Show me an example of a context graph."
But it's not possible because we've reached the second part: the noun vs verb problem.
@kidehen wants a noun: "Give me the blueprint so I know where the ditches are, but the problem is that a "context graph" is a ~verb.
If  you were shown an example or snippet, similar to what an agent would see, it would just look like an RDF, or a property graph, or JSON. Because the context graph isn't the serialisation format. It's one part of the whole system.
It's like asking someone to show you "a website" and they show you an HTML file. Whilst technically correct, it's missing the server, the database, the API, etc.
Part 4: The Operational Reality
Gil Feig (@GilFeig) cuts through the  debate with  "What Everyone Gets Wrong About Context."
"Context does not live in a neat pile of documents. It lives in other systems, usually someone else’s system. Your CRM. Your ticketing tool. Your data warehouse. Your billing provider. A calendar. A Slack workspace. Ten different SaaS tools, each with its own auth model, rate limits, and weird data quirks."
The actual hard problem is coordination.
"If you want a practical definition: a context graph is a coordination layer that turns 'I have access to a bunch of tools' into 'I can assemble the right slice of reality for this user, right now.'
His point is that the "context graph" isn't just a data structure.

It's a system that decides what should be seen by the agent because not everything is relevant all of the time. You have to figure out  how to stitch results together into something the model can use within it's limited context window.
And this is done by deciding what not to pull.
If  you're trying to fetch  "everything relevant", the output is always going to be worse because the agent will end up in the dumb zone  of the context window.

He breaks the 'laddering' of what to choose into three tiers: 
1. Live API calls
2. Cached snapshots 
3. Derived context like summaries and embeddings
And  then you need to factor in latency, cost, rate limits and context windows, as well as provenance.

You need each piece of context to answer where it came from, when was it fetched, was it transformed, etc.
When something goes wrong, the first question isn't "why did the model do that?" but "what did it see and what did we show it?"
The punchline:
"The graph is the easy part. The selection and enforcement logic is the product."
You know the parable of the blind men and the elephant?
So where does this leave us?
Jaya says it's decision trace capture
Animesh says it's a world model built by agent walks
Kirk says to adopt foundations, build temporal + resolution layers
Daniel says it's a methodology, use whatever works
Kingsley is asking to see the formal specification
Gil says it's a coordination layer and selection is the hard problem
They're all right about their part and they're all describing the same elephant.
Which brings us to Part 5...
Part 5: It's Not a Graph, It's a Flywheel
Here's my take after reading all of this: the different definitions of the term "context graph"  are just distinct steps within a flywheel.
blame gemini if there's in accuracy, i'm hitting context limits rn
The value is in the loop that makes it compound, not the graph you design.
This is because you will end up redesigning it regularly to keep up with agent capabilities, organisational changes, and business needs.
What we're actually talking about is a context flywheel.

Ingest → Store → Resolve → Retrieve → Serve → Agent acts → Capture → Ingest
Let me break this down:
Ingest: Extract structure from unstructured sources (Slack, email, docs, transcripts) 
Store:  Entities, relationships, facts (using adopted ontologies : Schema.org, RDF, whatever fits)
Resolve: Identity resolution (Sarah Chen = @ sarah = S. Chen) + fact resolution (what's canonical when sources conflict)
Temporal: When was this true? Is it still true? Facts with validity periods.
Retrieve: Semantic search, graph traversal, hybrid queries
Serve: Fit into context window, respect permissions, manage token budgets.
Coordinate:  Selection logic. What to fetch, what to skip. The hard problem Gil identified. 
Capture: Decision traces flow back into storage. The reasoning becomes data. 

How does this map to what everyone else is saying?
Jaya's decision traces -> Capture Layer

Kirk's Temporal Validity -> Temporal Layer

Daniel's Manifesto -> You can use any storage format

Gil's Coordination -> That's Serve + Coordinate

Animesh's world model & event clock->   Temporal  Layer & Compounding over spins 
The flywheel also shows why this is hard.
Every layer depends on the others:
You can't serve what you haven't retrieved
You can't retrieve what you haven't stored
You can't store what you haven't ingested
You can't resolve identities without entities to resolve
You can't capture decision traces without agents making decisions
Agents can't make good decisions without context
Context comes from what you've served  and breaks when you serve incorrectly
It's circular, each rotation increases  the "context clarity" the agent has but if you screw up one part, you'll compound garbage.
The business question:
Is this all one company serving a complete solution?

In my opinion, probably not. You could aim to become the "Palantir" of agents and build a team of 'forward deployed agents' and solve this for enterprise, but it doesn't mean you need to.
More likely: you pick one layer and own it.
Someone owns foundation + storage + temporal (Graphlit is betting here)
Someone owns methodology + flexibility (TrustGraph is betting here)
Someone owns decision trace capture (the opportunity Jaya identified)
Someone owns coordination + selection (the problem Gil articulated)
Someone building the compounding layer (Animesh's idea of world models)
The flywheel doesn't need to be one product from company, it just needs layers to exist and connect.
BUT WHAT ABOUT STANDARDISATION AND INTEROPERABILITY BRO?

There is one argument left that there should be a "standardisation" for the "context graph" but in my uninformed opinion, I don't believe that applies at the implementation layer.
If you're building for private utility (your own agents, organisation, etc), you're allowed to use whatever works.
Creating a universal system that works in every context and layer is going to be harder and more error-prone than just customising it to fit you.

The existing technologies, decades of research and ideas are there to be used, not re-invented.

And over time the  'context graph/flywheel/idk what to call it anymore sorry' becomes your competitive advantage, not a commodity. How you structure it for your specific case will determine how effective your agents are in production. 

And if we get meta for a second, each department gets its own agent + flywheel. And the data warehouse gets its own agent and this becomes the orchestration layer between everything else.

And now you're building a flywheel of flywheels but that's definitely another article (or I'm losing it - take your pick)
And If we're talking about  agent-to-agent communication across the public web, then sure something like RDF and shared ontologies probably kicks back in, and the semantic web might get its second act in the agent economy.
So when is something NOT a context graph?
When you can't trace 'what did the agent see when it made that decision?' and if the loop doesn't close (no capture, no compounding) means you've got a fancy database with an LLM stapled on top.

But hey, you could probably raise a few billion with that.
And when does the definition problem get solved?
Probably when the LLMs take over this debate and we're no longer needed to argue about it.
TL;DR:

I read all the articles so you don't have to. Everyone's asking "what is a context graph?" is asking the wrong question.

A context graph is just a snapshot. The real question is: what's needed to design the flywheel to make it compound.
Now if you'll excuse me, I need to go touch grass and forget everything I just learned about context graphs.

If there are any inaccuracies, misquotations,  misrepresentations or misunderstandings - I'm claiming this was AI generated.

And I'm sorry if this shows up on your feed @dejavucoder - I really tried not write this.

Further Reading:
Context Graphs: What the Ontology Debate Gets Wrong
What everyone is getting wrong about context
The Context Graph Manifesto
AI’s trillion-dollar opportunity: Context graphs
How To Build A Context Graph

11:42 PM · Jan 20, 2026
·
20.4K
 Views

